#!/usr/bin/env python
# coding: utf-8

# # Extracting action items from meetingnotes
# 

# In[2]:


pip install sagemaker


# In[9]:


import boto3
import json


# In[10]:


bedrock_runtime = boto3.client(
    service_name='bedrock-runtime',
    region_name='us-east-1')


# In[11]:


# Let's first test the AI21 model with a simple 'hello' prompt

prompt = 'hello'


# Define keywords arguments
kwargs = {
  "modelId": "ai21.j2-ultra-v1",
  "contentType": "application/json",
  "accept": "*/*",
  "body": "{\"prompt\":\"" + prompt + "\",\"maxTokens\":200,\"temperature\":0.7,\"topP\":1,\"stopSequences\":[\"##\"],\"countPenalty\":{\"scale\":0},\"presencePenalty\":{\"scale\":0},\"frequencyPenalty\":{\"scale\":0}}"
}

# print(kwargs)


# In[19]:


# Use the invoke_model API to call the AI21 model on Bedrock 

response = bedrock_runtime.invoke_model(**kwargs)
# print(response)

response_body = json.loads(response.get('body').read())


# In[20]:


# get the response from the model output.
completion = response_body.get('completions')[0].get('data').get('text')

print(completion)



# In[21]:


# Now we've tested our first prompt, we can extract action items from our meeting transcript.

prompt_data = """Below is a meeting transcript:

##

Sarah: Thanks for joining this meeting to discuss potential uses of generative AI for our new online learning platform. I think there are some exciting opportunities here.

Alex: I agree. AI could really enhance the learning experience for students. What specific ideas did you have in mind?

Sarah: Well, we could use it to generate personalized feedback for students on their writing assignments. The AI could analyze their work and provide tailored suggestions for improvement.

Alex: That's a great idea! Automated feedback would really help students improve their skills. And it would free up our instructors to focus on other teaching tasks.

Sarah: Exactly. We could also use generative AI for auto-grading of certain assignment types, like multiple choice quizzes. The AI could instantly grade submissions and provide scores.

Alex: Auto-grading would definitely create efficiencies. Though we'd still want human oversight for more complex assessments. What about using generative AI for chatbots? Like AI teaching assistants that students could ask questions?

Sarah: Oh yes, AI chatbots could be really useful! Students tend to learn better when they can get answers in real-time. The chatbots could handle common questions, and escalate more complex ones to human TAs.

Alex: Those are some solid use cases. This technology could really enhance our platform's capabilities. Though we'd need to validate the AI's accuracy. And have protocols for when human intervention is needed.

Sarah: Definitely. We should start testing some generative AI services using real student work samples. We can analyze the results and build out guidelines on how to best leverage the technology.

Alex: Sounds good. I'm excited about the potential here. Let's plan to reconvene next week after we've done some initial testing.

Sarah: Perfect. I'll get the ball rolling on that.

##

Identify action items for each person in this meeting transcript, if there are any.""".encode('unicode_escape').decode('utf-8')


# In[22]:


kwargs = {
  "modelId": "ai21.j2-ultra-v1",
  "contentType": "application/json",
  "accept": "*/*",
  "body": "{\"prompt\":\"" + prompt_data + "\",\"maxTokens\":5000,\"temperature\":0.7,\"topP\":1,\"stopSequences\":[\"##\"],\"countPenalty\":{\"scale\":0},\"presencePenalty\":{\"scale\":0},\"frequencyPenalty\":{\"scale\":0}}"
}

response = bedrock_runtime.invoke_model(**kwargs)


# In[23]:


response_body = json.loads(response.get('body').read())

# get the response from the model output.
output = response_body.get('completions')[0].get('data').get('text')

print(output)

